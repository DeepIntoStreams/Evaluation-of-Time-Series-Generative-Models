{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32271e1-351e-413f-81f7-8b16ee8e7b32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xdong\\anaconda3\\envs\\py38_deep\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import ml_collections\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import wandb\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "from src.baselines.models import get_trainer\n",
    "from unit_tests.test_utils import *\n",
    "from src.utils import loader_to_tensor, set_seed\n",
    "from src.datasets.dataloader import get_dataset\n",
    "from src.baselines.networks.TimeVAE import VariationalAutoencoderConvInterpretable\n",
    "from src.baselines.TimeVAE import TimeVAETrainer\n",
    "from src.evaluations.loss import get_standard_test_metrics\n",
    "from src.evaluations.evaluations import full_evaluation\n",
    "from src.evaluations.summary import full_evaluation_latest\n",
    "from unit_tests.test_utils import test_init\n",
    "from src.utils import combine_dls\n",
    "from src.utils import to_numpy\n",
    "from src.evaluations.loss import CrossCorrelLoss\n",
    "from src.evaluations.summary import EvaluationComponent, EvaluationSummary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cee29fd7-2d91-4f04-871e-4f53b50752cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = test_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6318e3b0-924a-46b6-97b8-1e5069e9cbf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestMetrics:\n",
       "  acf_loss:\n",
       "    stationary: true\n",
       "  cov_loss: None\n",
       "  cross_corr: None\n",
       "  discriminative_score:\n",
       "    dscore_batch_size: 128\n",
       "    dscore_epochs: 10\n",
       "    dscore_hidden_size: 32\n",
       "    dscore_num_layers: 1\n",
       "  hist_loss:\n",
       "    n_bins: 50\n",
       "  permutation_test:\n",
       "    n_permutation: 5\n",
       "  predictive_score:\n",
       "    pscore_batch_size: 128\n",
       "    pscore_epochs: 10\n",
       "    pscore_hidden_size: 32\n",
       "    pscore_num_layers: 2\n",
       "  sig_mmd:\n",
       "    depth: 5\n",
       "  sigw1_loss:\n",
       "    depth: 2\n",
       "batch_size: 256\n",
       "metrics_enabled:\n",
       "- cross_corr\n",
       "n_eval: 5\n",
       "sample_size: 1000\n",
       "test_ratio: 0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['Evaluation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2727b6-f061-4ab0-b86b-424005bdd7b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Full evaluation latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044c6e8-62ec-43d8-b751-4f455cbe5fb6",
   "metadata": {},
   "source": [
    "#### Step 1: Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8d949f35-fdbd-47e1-bf0f-18d9ce47d951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fn = lambda filename: pt.join(config.data_dir, filename)\n",
    "\n",
    "# load pre-trained model\n",
    "vae = torch.load(fn('vae_model_state_dict.pt'))\n",
    "vae.encoder.load_state_dict(torch.load(fn('vae_encoder_state_dict.pt')), strict=True)\n",
    "vae.decoder.load_state_dict(torch.load(fn('vae_decoder_state_dict.pt')), strict=True)\n",
    "vae.eval()\n",
    "\n",
    "### data\n",
    "real_train_dl = torch.load(pt.join(config.data_dir, 'X_train.pt'))\n",
    "real_test_dl = torch.load(pt.join(config.data_dir, 'X_test.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7cfeff-f61d-4c93-bf22-3e02ad4ed4d0",
   "metadata": {},
   "source": [
    "#### Step 2: call full_evaluation_latest -> EvaluationSummary result class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87357a7f-b4d0-4638-8bfd-ec0d44ecaa59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- evaluation metric = cross_corr in group = stylized_fact_scores ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No metrics enabled in group = implicit_scores\n",
      " No metrics enabled in group = sig_scores\n",
      " No metrics enabled in group = permutation_test\n",
      "EvaluationSummary(cross_corr_mean=0.22479782, cross_corr_std=0.03149462, hist_loss_mean=nan, hist_loss_std=nan, cov_loss_mean=nan, cov_loss_std=nan, acf_loss_mean=nan, acf_loss_std=nan, sigw1_mean=nan, sigw1_std=nan, sig_mmd_mean=nan, sig_mmd_std=nan, discriminative_score_mean=nan, discriminative_score_std=nan, predictive_score_mean=nan, predictive_score_std=nan, permutation_test_power=nan, permutation_test_type1_error=nan)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_summary = full_evaluation_latest(vae, real_train_dl, real_test_dl, config, algo='TimeVAE')       \n",
    "print(eval_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17777e67-8ccd-4f70-98ca-cafc965ef467",
   "metadata": {},
   "source": [
    "#### Zoom in `full_evaluation_latest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb6c0cc3-007a-407c-ab50-ba5bfc53862b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- evaluation metric = cross_corr in group = stylized_fact_scores ----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 28.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No metrics enabled in group = implicit_scores\n",
      " No metrics enabled in group = sig_scores\n",
      " No metrics enabled in group = permutation_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvaluationSummary(cross_corr_mean=0.24386013, cross_corr_std=0.020164223, hist_loss_mean=nan, hist_loss_std=nan, cov_loss_mean=nan, cov_loss_std=nan, acf_loss_mean=nan, acf_loss_std=nan, sigw1_mean=nan, sigw1_std=nan, sig_mmd_mean=nan, sig_mmd_std=nan, discriminative_score_mean=nan, discriminative_score_std=nan, predictive_score_mean=nan, predictive_score_std=nan, permutation_test_power=nan, permutation_test_type1_error=nan)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1: \n",
    "ec = EvaluationComponent(config, vae, real_train_dl, real_test_dl, **{'algo':'TimeVAE'})\n",
    "summary_dict = ec.eval_summary()\n",
    "# step 2: \n",
    "eval_summary = EvaluationSummary()\n",
    "eval_summary.set_values(summary_dict)\n",
    "eval_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b131475-a2e2-446c-8080-7feedcd53c5e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_corr_mean 0.22479782\n",
      "cross_corr_std 0.03149462\n",
      "hist_loss_mean nan\n",
      "hist_loss_std nan\n",
      "cov_loss_mean nan\n",
      "cov_loss_std nan\n",
      "acf_loss_mean nan\n",
      "acf_loss_std nan\n",
      "sigw1_mean nan\n",
      "sigw1_std nan\n",
      "sig_mmd_mean nan\n",
      "sig_mmd_std nan\n",
      "discriminative_score_mean nan\n",
      "discriminative_score_std nan\n",
      "predictive_score_mean nan\n",
      "predictive_score_std nan\n",
      "permutation_test_power nan\n",
      "permutation_test_type1_error nan\n"
     ]
    }
   ],
   "source": [
    "# print result\n",
    "for k in eval_summary.get_attrs():\n",
    "    print(k,getattr(eval_summary,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d5213-a6bb-4f2b-953e-ac06e034e725",
   "metadata": {},
   "source": [
    "## Compute Metrics Details in `EvaluationComponent`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3fc4a3f1-b8be-4632-a463-59deeb916eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data includes  dict_keys(['real_train_dl', 'real_test_dl', 'fake_train_dl', 'fake_test_dl'])\n",
      "cross_corr = 0.25324398279190063\n",
      "cross_corr = 0.25324398279190063\n",
      "cross_corr = 0.25324398279190063\n"
     ]
    }
   ],
   "source": [
    "# Crreate evaluation component from (config, model, train_data, test_data)\n",
    "eval_comp = EvaluationComponent(config, vae, real_train_dl, real_test_dl, **{'algo':'TimeVAE'})\n",
    "\n",
    "# data\n",
    "data_map = eval_comp.data_set[0]\n",
    "print('data includes ',data_map.keys())\n",
    "real = combine_dls([data_map['real_train_dl'],data_map['real_test_dl']])\n",
    "fake = combine_dls([data_map['fake_train_dl'],data_map['fake_test_dl']]) \n",
    "\n",
    "#### Metrics\n",
    "\n",
    "## method 1\n",
    "metric = 'cross_corr'\n",
    "eval_func = getattr(eval_comp, metric)\n",
    "score = eval_func(real,fake)\n",
    "print(f'{metric} = {score}')\n",
    "\n",
    "\n",
    "## method 2\n",
    "scores2 = eval_comp.cross_corr(real,fake)\n",
    "print(f'{metric} = {scores2}')\n",
    "\n",
    "## method 2\n",
    "scores3 = to_numpy(CrossCorrelLoss(real, name='cross_corr')(fake))\n",
    "print(f'{metric} = {scores3}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae417c11-9b1b-4ecf-98f3-fb26acca9412",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "class CrossCorrelLoss(Loss):\n",
    "    def __init__(self, x_real, max_lag=64, **kwargs):\n",
    "        super(CrossCorrelLoss, self).__init__(norm_foo=cc_diff, **kwargs)\n",
    "        self.lags = max_lag\n",
    "        self.metric = CrossCorrelationMetric(self.transform)\n",
    "        self.cross_correl_real = self.metric.measure(x_real,self.lags).mean(0)[0]\n",
    "        self.max_lag = max_lag\n",
    "\n",
    "    def compute(self, x_fake):\n",
    "        cross_correl_fake = self.metric.measure(x_fake,lags=self.lags).mean(0)[0]\n",
    "        loss = self.norm_foo(\n",
    "            cross_correl_fake - self.cross_correl_real.to(x_fake.device)).unsqueeze(0)\n",
    "        return loss\n",
    "'''\n",
    "# from src.evaluations.metrics import CrossCorrelationMetric\n",
    "# m = CrossCorrelationMetric()\n",
    "# cc_real = m.measure(real,lags=64).mean(0)[0]\n",
    "# cc_fake = m.measure(fake,lags=64).mean(0)[0]\n",
    "# cc = torch.abs((cc_fake - cc_real.to(cc_fake.device))).sum(0).unsqueeze(0)\n",
    "# cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38_deep",
   "language": "python",
   "name": "py38_deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
